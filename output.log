nohup: ignoring input
2024-12-13 00:14:49.346792: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-12-13 00:14:49.359416: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1734066889.371327 1272226 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1734066889.374648 1272226 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-12-13 00:14:49.387377: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:tensorflow:From /home/accts/ltp8/.local/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
/home/accts/ltp8/Desktop/CPSC483_finalproject/utility/loader_kgat.py:88: RuntimeWarning: divide by zero encountered in power
  d_inv = np.power(rowsum, -1).flatten()
WARNING:tensorflow:From /home/accts/ltp8/.local/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
I0000 00:00:1734066905.141105 1272226 gpu_process_state.cc:201] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1734066905.142414 1272226 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14170 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080, pci bus id: 0000:4e:00.0, compute capability: 8.9
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1734066905.228159 1272226 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled
/home/accts/ltp8/Desktop/CPSC483_finalproject/main_2hop.py:314: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)
  perf_str = 'Epoch %d [%.1fs]: train==[%.5f=%.5f + %.5f + %.5f]' % (
Current global policy: <DTypePolicy "mixed_float16">
pathways read
len of iter_mat: 60628
len of user_dict: 11048
len of iter_mat: 14311
len of user_dict: 11048
read in files
	convert ratings into adj mat done.
	convert 6 relational triples into adj mat done. @0.0095s
	generate si-normalized adjacency matrix.
Reordering and sorting indices...
Sorting completed. Validated lengths of lists.
using xavier initialization
A_fold_hat created
(1171, 117120)
(117120, 32)
Embeddings made with shape: (117120, 32)
Side embeddings made with shape: (117120, 32)
Add embeddings with shape: (117120, 32)
Sum embeddings with shape: (117120, 64)
Bi embeddings with shape: (117120, 32)
Transformed bi embeddings with shape: (117120, 64)
Ego embeddings after addition with shape: (117120, 64)
Dropout ego embeddings with shape: (117120, 64)
Normalized embeddings with shape: (117120, 64)
added to all embeddings
Side embeddings made with shape: (117120, 64)
Add embeddings with shape: (117120, 64)
Sum embeddings with shape: (117120, 32)
Bi embeddings with shape: (117120, 64)
Transformed bi embeddings with shape: (117120, 32)
Ego embeddings after addition with shape: (117120, 32)
Dropout ego embeddings with shape: (117120, 32)
Normalized embeddings with shape: (117120, 32)
added to all embeddings
Side embeddings made with shape: (117120, 32)
Add embeddings with shape: (117120, 32)
Sum embeddings with shape: (117120, 16)
Bi embeddings with shape: (117120, 32)
Transformed bi embeddings with shape: (117120, 16)
Ego embeddings after addition with shape: (117120, 16)
Dropout ego embeddings with shape: (117120, 16)
Normalized embeddings with shape: (117120, 16)
added to all embeddings
Final all embeddings shape: (117120, 144)
calculated 2-hop attention
#params: 3772944
model and saver created
without pretraining.
-----------------------------------------------------------------
Starting Training!
-----------------------------------------------------------------
index: 0, 0.0
index: 100, 0.10559662090813093
index: 200, 0.21119324181626187
index: 300, 0.3167898627243928
index: 400, 0.42238648363252373
index: 500, 0.5279831045406547
index: 600, 0.6335797254487856
index: 700, 0.7391763463569165
index: 800, 0.8447729672650475
index: 900, 0.9503695881731784
Iteration 0/2209
Iteration 100/2209
Iteration 200/2209
Iteration 300/2209
Iteration 400/2209
Iteration 500/2209
Iteration 600/2209
Iteration 700/2209
Iteration 800/2209
Iteration 900/2209
Iteration 1000/2209
Iteration 1100/2209
Iteration 1200/2209
Iteration 1300/2209
Iteration 1400/2209
Iteration 1500/2209
Iteration 1600/2209
Iteration 1700/2209
Iteration 1800/2209
Iteration 1900/2209
Iteration 2000/2209
Iteration 2100/2209
Iteration 2200/2209
updating attentive laplacian matrix
Epoch 0 [33.9s]: train==[2165.77881=638.41786 + 1527.31616 + 0.04490]
-----------------------------------------------------------------
Starting Testing!
-----------------------------------------------------------------
Result:  {'precision': array([0.00062455, 0.00059513, 0.00061399, 0.00062455, 0.00061459]), 'recall': array([0.00948135, 0.01828385, 0.02761435, 0.03807627, 0.04675809]), 'ndcg': array([0.00400517, 0.00626054, 0.00852615, 0.01060971, 0.01233328]), 'hit_ratio': array([0.01240043, 0.02353367, 0.03638668, 0.04905865, 0.05992035]), 'auc': 0.5709693325970308}
performance logging
save the weights in path:  weights/taobao_scarce/kgat_si_sum_bi_l3/64-32-16/l0.0001_r1e-05-1e-05-0.01
index: 0, 0.0
index: 100, 0.10559662090813093
index: 200, 0.21119324181626187
index: 300, 0.3167898627243928
index: 400, 0.42238648363252373
index: 500, 0.5279831045406547
index: 600, 0.6335797254487856
index: 700, 0.7391763463569165
index: 800, 0.8447729672650475
index: 900, 0.9503695881731784
Iteration 0/2209
Iteration 100/2209
Iteration 200/2209
Iteration 300/2209
Iteration 400/2209
Iteration 500/2209
Iteration 600/2209
Iteration 700/2209
Iteration 800/2209
Iteration 900/2209
Iteration 1000/2209
Iteration 1100/2209
Iteration 1200/2209
Iteration 1300/2209
Iteration 1400/2209
Iteration 1500/2209
Iteration 1600/2209
Iteration 1700/2209
Iteration 1800/2209
Iteration 1900/2209
Iteration 2000/2209
Iteration 2100/2209
Iteration 2200/2209
updating attentive laplacian matrix
-----------------------------------------------------------------
Starting Testing!
-----------------------------------------------------------------
WARNING:tensorflow:From /home/accts/ltp8/.local/lib/python3.10/site-packages/tensorflow/python/training/saver.py:1068: remove_checkpoint (from tensorflow.python.checkpoint.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
